{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c7ba1b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-02T14:17:28.788605Z",
     "iopub.status.busy": "2025-07-02T14:17:28.788109Z",
     "iopub.status.idle": "2025-07-02T14:17:35.081015Z",
     "shell.execute_reply": "2025-07-02T14:17:35.079740Z"
    },
    "papermill": {
     "duration": 6.303476,
     "end_time": "2025-07-02T14:17:35.083423",
     "exception": false,
     "start_time": "2025-07-02T14:17:28.779947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/widsdatathon2025/SAMPLE_SUBMISSION.xlsx\n",
      "/kaggle/input/widsdatathon2025/Data Dictionary.xlsx\n",
      "/kaggle/input/widsdatathon2025/TRAIN_OLD/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv\n",
      "/kaggle/input/widsdatathon2025/TRAIN_OLD/TRAINING_SOLUTIONS.xlsx\n",
      "/kaggle/input/widsdatathon2025/TRAIN_OLD/TRAIN_CATEGORICAL_METADATA.xlsx\n",
      "/kaggle/input/widsdatathon2025/TRAIN_OLD/TRAIN_QUANTITATIVE_METADATA.xlsx\n",
      "/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAINING_SOLUTIONS.xlsx\n",
      "/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv\n",
      "/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAIN_CATEGORICAL_METADATA_new.xlsx\n",
      "/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAIN_QUANTITATIVE_METADATA_new.xlsx\n",
      "/kaggle/input/widsdatathon2025/TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv\n",
      "/kaggle/input/widsdatathon2025/TEST/TEST_CATEGORICAL.xlsx\n",
      "/kaggle/input/widsdatathon2025/TEST/TEST_QUANTITATIVE_METADATA.xlsx\n"
     ]
    }
   ],
   "source": [
    "#This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from scipy.stats import zscore, pearsonr, uniform\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RandomizedSearchCV\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d17d06a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:17:35.097394Z",
     "iopub.status.busy": "2025-07-02T14:17:35.096807Z",
     "iopub.status.idle": "2025-07-02T14:17:59.699751Z",
     "shell.execute_reply": "2025-07-02T14:17:59.698463Z"
    },
    "papermill": {
     "duration": 24.610778,
     "end_time": "2025-07-02T14:17:59.701423",
     "exception": false,
     "start_time": "2025-07-02T14:17:35.090645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/196046770.py:13: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  train_encoded = train_encoded.applymap(lambda x: 1 if x is True else (0 if x is False else x))\n",
      "/tmp/ipykernel_13/196046770.py:40: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  test_encoded = test_encoded.applymap(lambda x: 1 if x is True else (0 if x is False else x))\n"
     ]
    }
   ],
   "source": [
    "#Caricamento del dataset di train\n",
    "train_cat = pd.read_excel (\"/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAIN_CATEGORICAL_METADATA_new.xlsx\")\n",
    "train_quant = pd.read_excel(\"/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAIN_QUANTITATIVE_METADATA_new.xlsx\")\n",
    "train_fmri = pd.read_csv(\"/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv\")\n",
    "train_sol = pd.read_excel(\"/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAINING_SOLUTIONS.xlsx\")\n",
    "\n",
    "#One hot encoding dei dati categorici\n",
    "for col in train_cat.select_dtypes(include='int').columns:\n",
    "    train_cat[col] = train_cat[col].astype('category')\n",
    "\n",
    "columns_to_encode = train_cat.columns[1:].tolist()\n",
    "train_encoded = pd.get_dummies(train_cat[columns_to_encode], drop_first=True)\n",
    "train_encoded = train_encoded.applymap(lambda x: 1 if x is True else (0 if x is False else x))\n",
    "\n",
    "cat_train_final = pd.concat([train_cat.drop(columns=columns_to_encode), train_encoded], axis=1)\n",
    "cat_train_final.head()\n",
    "\n",
    "\n",
    "#Merging dei dati categorici (dopo aver fatto l'encoding) con i dati quantitativi e le soluzioni, per ottenere il dataset dei dati demografici\n",
    "train_demo = pd.merge(cat_train_final, train_quant, on = 'participant_id')\n",
    "train_final_demo = pd.merge(train_demo, train_sol, on = 'participant_id')\n",
    "train_final_demo.head()\n",
    "\n",
    "#Merging dei dati fmri le soluzioni, per ottenere il dataset dei dati di connettivitÃ \n",
    "train_final_connett = pd.merge(train_fmri, train_sol, on = 'participant_id')\n",
    "train_final_connett.head()\n",
    "\n",
    "\n",
    "#Caricamento del dataset di test\n",
    "test_cat = pd.read_excel(\"/kaggle/input/widsdatathon2025/TEST/TEST_CATEGORICAL.xlsx\")\n",
    "test_quant = pd.read_excel(\"/kaggle/input/widsdatathon2025/TEST/TEST_QUANTITATIVE_METADATA.xlsx\")\n",
    "test_fmri = pd.read_csv(\"/kaggle/input/widsdatathon2025/TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv\")\n",
    "\n",
    "#One hot encoding dei dati categorici\n",
    "for col in test_cat.select_dtypes(include='int').columns:\n",
    "    test_cat[col] = test_cat[col].astype('category')\n",
    "\n",
    "columns_to_encode = test_cat.columns[1:].tolist()\n",
    "test_encoded = pd.get_dummies(test_cat[columns_to_encode], drop_first=True)\n",
    "test_encoded = test_encoded.applymap(lambda x: 1 if x is True else (0 if x is False else x))\n",
    "\n",
    "cat_test_final = pd.concat([test_cat.drop(columns=columns_to_encode), test_encoded], axis=1)\n",
    "cat_test_final.head()\n",
    "\n",
    "\n",
    "#Merging dei dati categorici (dopo aver fatto l'encoding) con i dati quantitativi, per ottenere il dataset dei dati demografici\n",
    "test_final_demo = pd.merge(cat_test_final, test_quant, on = 'participant_id')\n",
    "test_final_demo.head()\n",
    "\n",
    "#Cambio il nome dei dati fmri per ottenere il dataset dei dati di connettivitÃ \n",
    "test_final_connett = test_fmri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a7c7ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:17:59.712988Z",
     "iopub.status.busy": "2025-07-02T14:17:59.712631Z",
     "iopub.status.idle": "2025-07-02T14:17:59.771069Z",
     "shell.execute_reply": "2025-07-02T14:17:59.769808Z"
    },
    "papermill": {
     "duration": 0.067124,
     "end_time": "2025-07-02T14:17:59.773428",
     "exception": false,
     "start_time": "2025-07-02T14:17:59.706304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant_id                        0\n",
      "PreInt_Demos_Fam_Child_Ethnicity     43\n",
      "PreInt_Demos_Fam_Child_Race          54\n",
      "MRI_Track_Scan_Location               3\n",
      "Barratt_Barratt_P1_Edu               15\n",
      "Barratt_Barratt_P1_Occ               31\n",
      "Barratt_Barratt_P2_Edu              198\n",
      "Barratt_Barratt_P2_Occ              222\n",
      "Basic_Demos_Enroll_Year_2016          0\n",
      "Basic_Demos_Enroll_Year_2017          0\n",
      "Basic_Demos_Enroll_Year_2018          0\n",
      "Basic_Demos_Enroll_Year_2019          0\n",
      "Basic_Demos_Enroll_Year_2020          0\n",
      "Basic_Demos_Study_Site_2              0\n",
      "Basic_Demos_Study_Site_3              0\n",
      "Basic_Demos_Study_Site_4              0\n",
      "EHQ_EHQ_Total                        13\n",
      "ColorVision_CV_Score                 23\n",
      "APQ_P_APQ_P_CP                       12\n",
      "APQ_P_APQ_P_ID                       12\n",
      "APQ_P_APQ_P_INV                      12\n",
      "APQ_P_APQ_P_OPD                      12\n",
      "APQ_P_APQ_P_PM                       12\n",
      "APQ_P_APQ_P_PP                       12\n",
      "SDQ_SDQ_Conduct_Problems              9\n",
      "SDQ_SDQ_Difficulties_Total            9\n",
      "SDQ_SDQ_Emotional_Problems            9\n",
      "SDQ_SDQ_Externalizing                 9\n",
      "SDQ_SDQ_Generating_Impact             9\n",
      "SDQ_SDQ_Hyperactivity                 9\n",
      "SDQ_SDQ_Internalizing                 9\n",
      "SDQ_SDQ_Peer_Problems                 9\n",
      "SDQ_SDQ_Prosocial                     9\n",
      "MRI_Track_Age_at_Scan               360\n",
      "ADHD_Outcome                          0\n",
      "Sex_F                                 0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "participant_id                      0\n",
      "PreInt_Demos_Fam_Child_Ethnicity    0\n",
      "PreInt_Demos_Fam_Child_Race         0\n",
      "MRI_Track_Scan_Location             0\n",
      "Barratt_Barratt_P1_Edu              0\n",
      "Barratt_Barratt_P1_Occ              0\n",
      "Barratt_Barratt_P2_Edu              0\n",
      "Barratt_Barratt_P2_Occ              0\n",
      "Basic_Demos_Enroll_Year_2016        0\n",
      "Basic_Demos_Enroll_Year_2017        0\n",
      "Basic_Demos_Enroll_Year_2018        0\n",
      "Basic_Demos_Enroll_Year_2019        0\n",
      "Basic_Demos_Enroll_Year_2020        0\n",
      "Basic_Demos_Study_Site_2            0\n",
      "Basic_Demos_Study_Site_3            0\n",
      "Basic_Demos_Study_Site_4            0\n",
      "EHQ_EHQ_Total                       0\n",
      "ColorVision_CV_Score                0\n",
      "APQ_P_APQ_P_CP                      0\n",
      "APQ_P_APQ_P_ID                      0\n",
      "APQ_P_APQ_P_INV                     0\n",
      "APQ_P_APQ_P_OPD                     0\n",
      "APQ_P_APQ_P_PM                      0\n",
      "APQ_P_APQ_P_PP                      0\n",
      "SDQ_SDQ_Conduct_Problems            0\n",
      "SDQ_SDQ_Difficulties_Total          0\n",
      "SDQ_SDQ_Emotional_Problems          0\n",
      "SDQ_SDQ_Externalizing               0\n",
      "SDQ_SDQ_Generating_Impact           0\n",
      "SDQ_SDQ_Hyperactivity               0\n",
      "SDQ_SDQ_Internalizing               0\n",
      "SDQ_SDQ_Peer_Problems               0\n",
      "SDQ_SDQ_Prosocial                   0\n",
      "MRI_Track_Age_at_Scan               0\n",
      "ADHD_Outcome                        0\n",
      "Sex_F                               0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "0\n",
      "participant_id                       0\n",
      "PreInt_Demos_Fam_Child_Ethnicity     3\n",
      "PreInt_Demos_Fam_Child_Race          6\n",
      "Barratt_Barratt_P1_Edu               1\n",
      "Barratt_Barratt_P1_Occ               1\n",
      "Barratt_Barratt_P2_Edu              36\n",
      "Barratt_Barratt_P2_Occ              42\n",
      "Basic_Demos_Enroll_Year_2020         0\n",
      "Basic_Demos_Enroll_Year_2021         0\n",
      "Basic_Demos_Enroll_Year_2022         0\n",
      "Basic_Demos_Enroll_Year_2023         0\n",
      "Basic_Demos_Study_Site_5             0\n",
      "MRI_Track_Scan_Location_4            0\n",
      "EHQ_EHQ_Total                        1\n",
      "ColorVision_CV_Score                 9\n",
      "APQ_P_APQ_P_CP                      15\n",
      "APQ_P_APQ_P_ID                      15\n",
      "APQ_P_APQ_P_INV                     15\n",
      "APQ_P_APQ_P_OPD                     15\n",
      "APQ_P_APQ_P_PM                      15\n",
      "APQ_P_APQ_P_PP                      15\n",
      "SDQ_SDQ_Conduct_Problems            30\n",
      "SDQ_SDQ_Difficulties_Total          30\n",
      "SDQ_SDQ_Emotional_Problems          30\n",
      "SDQ_SDQ_Externalizing               30\n",
      "SDQ_SDQ_Generating_Impact           30\n",
      "SDQ_SDQ_Hyperactivity               30\n",
      "SDQ_SDQ_Internalizing               30\n",
      "SDQ_SDQ_Peer_Problems               30\n",
      "SDQ_SDQ_Prosocial                   30\n",
      "MRI_Track_Age_at_Scan                0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "participant_id                      0\n",
      "PreInt_Demos_Fam_Child_Ethnicity    0\n",
      "PreInt_Demos_Fam_Child_Race         0\n",
      "Barratt_Barratt_P1_Edu              0\n",
      "Barratt_Barratt_P1_Occ              0\n",
      "Barratt_Barratt_P2_Edu              0\n",
      "Barratt_Barratt_P2_Occ              0\n",
      "Basic_Demos_Enroll_Year_2020        0\n",
      "Basic_Demos_Enroll_Year_2021        0\n",
      "Basic_Demos_Enroll_Year_2022        0\n",
      "Basic_Demos_Enroll_Year_2023        0\n",
      "Basic_Demos_Study_Site_5            0\n",
      "MRI_Track_Scan_Location_4           0\n",
      "EHQ_EHQ_Total                       0\n",
      "ColorVision_CV_Score                0\n",
      "APQ_P_APQ_P_CP                      0\n",
      "APQ_P_APQ_P_ID                      0\n",
      "APQ_P_APQ_P_INV                     0\n",
      "APQ_P_APQ_P_OPD                     0\n",
      "APQ_P_APQ_P_PM                      0\n",
      "APQ_P_APQ_P_PP                      0\n",
      "SDQ_SDQ_Conduct_Problems            0\n",
      "SDQ_SDQ_Difficulties_Total          0\n",
      "SDQ_SDQ_Emotional_Problems          0\n",
      "SDQ_SDQ_Externalizing               0\n",
      "SDQ_SDQ_Generating_Impact           0\n",
      "SDQ_SDQ_Hyperactivity               0\n",
      "SDQ_SDQ_Internalizing               0\n",
      "SDQ_SDQ_Peer_Problems               0\n",
      "SDQ_SDQ_Prosocial                   0\n",
      "MRI_Track_Age_at_Scan               0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Controllo quanti valori nulli ci sono nel dataset di train\n",
    "print(train_final_demo.isna().sum())\n",
    "\n",
    "#Sostituisco i valori mancanti delle variabili categoriche con la moda\n",
    "train_final_demo['PreInt_Demos_Fam_Child_Ethnicity'] = train_final_demo['PreInt_Demos_Fam_Child_Ethnicity'].fillna(train_final_demo['PreInt_Demos_Fam_Child_Ethnicity'].mode()[0])\n",
    "train_final_demo['PreInt_Demos_Fam_Child_Race'] = train_final_demo['PreInt_Demos_Fam_Child_Race'].fillna(train_final_demo['PreInt_Demos_Fam_Child_Race'].mode()[0])\n",
    "train_final_demo['MRI_Track_Scan_Location'] = train_final_demo['MRI_Track_Scan_Location'].fillna(train_final_demo['MRI_Track_Scan_Location'].mode()[0])\n",
    "train_final_demo['Barratt_Barratt_P1_Edu'] = train_final_demo['Barratt_Barratt_P1_Edu'].fillna(train_final_demo['Barratt_Barratt_P1_Edu'].mode()[0])\n",
    "train_final_demo['Barratt_Barratt_P1_Occ'] = train_final_demo['Barratt_Barratt_P1_Occ'].fillna(train_final_demo['Barratt_Barratt_P1_Occ'].mode()[0])\n",
    "train_final_demo['Barratt_Barratt_P2_Edu'] = train_final_demo['Barratt_Barratt_P2_Edu'].fillna(train_final_demo['Barratt_Barratt_P2_Edu'].mode()[0])\n",
    "train_final_demo['Barratt_Barratt_P2_Occ'] = train_final_demo['Barratt_Barratt_P2_Occ'].fillna(train_final_demo['Barratt_Barratt_P2_Occ'].mode()[0])\n",
    "\n",
    "#Sostituisco i valori mancanti delle variabili quantitative con la media\n",
    "train_final_demo.fillna({'EHQ_EHQ_Total':train_final_demo['EHQ_EHQ_Total'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'ColorVision_CV_Score':train_final_demo['ColorVision_CV_Score'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'APQ_P_APQ_P_CP':train_final_demo['APQ_P_APQ_P_CP'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'APQ_P_APQ_P_ID':train_final_demo['APQ_P_APQ_P_ID'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'APQ_P_APQ_P_INV':train_final_demo['APQ_P_APQ_P_INV'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'APQ_P_APQ_P_OPD':train_final_demo['APQ_P_APQ_P_OPD'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'APQ_P_APQ_P_PM':train_final_demo['APQ_P_APQ_P_PM'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'APQ_P_APQ_P_PP':train_final_demo['APQ_P_APQ_P_PP'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'SDQ_SDQ_Conduct_Problems':train_final_demo['SDQ_SDQ_Conduct_Problems'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'SDQ_SDQ_Difficulties_Total':train_final_demo['SDQ_SDQ_Difficulties_Total'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'SDQ_SDQ_Emotional_Problems':train_final_demo['SDQ_SDQ_Emotional_Problems'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'SDQ_SDQ_Externalizing':train_final_demo['SDQ_SDQ_Externalizing'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'SDQ_SDQ_Generating_Impact':train_final_demo['SDQ_SDQ_Generating_Impact'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'SDQ_SDQ_Hyperactivity':train_final_demo['SDQ_SDQ_Hyperactivity'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'SDQ_SDQ_Internalizing':train_final_demo['SDQ_SDQ_Internalizing'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'SDQ_SDQ_Peer_Problems':train_final_demo['SDQ_SDQ_Peer_Problems'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'SDQ_SDQ_Prosocial':train_final_demo['SDQ_SDQ_Prosocial'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'MRI_Track_Age_at_Scan':train_final_demo['MRI_Track_Age_at_Scan'].mean()}, inplace = True)\n",
    "\n",
    "#Ora non ci sono piÃ¹ NaN values\n",
    "print('\\n\\n')\n",
    "print(train_final_demo.isna().sum())\n",
    "print('\\n')\n",
    "print(train_final_demo.isna().sum().sum())\n",
    "\n",
    "\n",
    "#Controllo quanti valori nulli ci sono nel dataset di test\n",
    "print(test_final_demo.isna().sum())\n",
    "\n",
    "#Sostituisco i valori mancanti delle variabili categoriche con la moda\n",
    "test_final_demo['PreInt_Demos_Fam_Child_Ethnicity'] = test_final_demo['PreInt_Demos_Fam_Child_Ethnicity'].fillna(test_final_demo['PreInt_Demos_Fam_Child_Ethnicity'].mode()[0])\n",
    "test_final_demo['PreInt_Demos_Fam_Child_Race'] = test_final_demo['PreInt_Demos_Fam_Child_Race'].fillna(test_final_demo['PreInt_Demos_Fam_Child_Race'].mode()[0])\n",
    "test_final_demo['Barratt_Barratt_P1_Edu'] = test_final_demo['Barratt_Barratt_P1_Edu'].fillna(test_final_demo['Barratt_Barratt_P1_Edu'].mode()[0])\n",
    "test_final_demo['Barratt_Barratt_P1_Occ'] = test_final_demo['Barratt_Barratt_P1_Occ'].fillna(test_final_demo['Barratt_Barratt_P1_Occ'].mode()[0])\n",
    "test_final_demo['Barratt_Barratt_P2_Edu'] = test_final_demo['Barratt_Barratt_P2_Edu'].fillna(test_final_demo['Barratt_Barratt_P2_Edu'].mode()[0])\n",
    "test_final_demo['Barratt_Barratt_P2_Occ'] = test_final_demo['Barratt_Barratt_P2_Occ'].fillna(test_final_demo['Barratt_Barratt_P2_Occ'].mode()[0])\n",
    "\n",
    "# Sostituisco i valori mancanti delle variabili quantitative con la media\n",
    "test_final_demo.fillna({'EHQ_EHQ_Total': test_final_demo['EHQ_EHQ_Total'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'ColorVision_CV_Score': test_final_demo['ColorVision_CV_Score'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'APQ_P_APQ_P_CP': test_final_demo['APQ_P_APQ_P_CP'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'APQ_P_APQ_P_ID': test_final_demo['APQ_P_APQ_P_ID'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'APQ_P_APQ_P_INV': test_final_demo['APQ_P_APQ_P_INV'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'APQ_P_APQ_P_OPD': test_final_demo['APQ_P_APQ_P_OPD'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'APQ_P_APQ_P_PM': test_final_demo['APQ_P_APQ_P_PM'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'APQ_P_APQ_P_PP': test_final_demo['APQ_P_APQ_P_PP'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'SDQ_SDQ_Conduct_Problems': test_final_demo['SDQ_SDQ_Conduct_Problems'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'SDQ_SDQ_Difficulties_Total': test_final_demo['SDQ_SDQ_Difficulties_Total'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'SDQ_SDQ_Emotional_Problems': test_final_demo['SDQ_SDQ_Emotional_Problems'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'SDQ_SDQ_Externalizing': test_final_demo['SDQ_SDQ_Externalizing'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'SDQ_SDQ_Generating_Impact': test_final_demo['SDQ_SDQ_Generating_Impact'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'SDQ_SDQ_Hyperactivity': test_final_demo['SDQ_SDQ_Hyperactivity'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'SDQ_SDQ_Internalizing': test_final_demo['SDQ_SDQ_Internalizing'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'SDQ_SDQ_Peer_Problems': test_final_demo['SDQ_SDQ_Peer_Problems'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'SDQ_SDQ_Prosocial': test_final_demo['SDQ_SDQ_Prosocial'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'MRI_Track_Age_at_Scan': test_final_demo['MRI_Track_Age_at_Scan'].mean()}, inplace=True)\n",
    "\n",
    "\n",
    "#Ora non ci sono piÃ¹ NaN values\n",
    "print('\\n\\n')\n",
    "print(test_final_demo.isna().sum())\n",
    "print('\\n')\n",
    "print(test_final_demo.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07f143c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:17:59.785172Z",
     "iopub.status.busy": "2025-07-02T14:17:59.784798Z",
     "iopub.status.idle": "2025-07-02T14:18:00.023433Z",
     "shell.execute_reply": "2025-07-02T14:18:00.022200Z"
    },
    "papermill": {
     "duration": 0.246682,
     "end_time": "2025-07-02T14:18:00.025199",
     "exception": false,
     "start_time": "2025-07-02T14:17:59.778517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === FEATURE SELECTION MANUALE PER DATI DI CONNETTIVITÃ€ ===\n",
    "#DATI DI TRAIN\n",
    "\n",
    "# Numeri interi che vuoi cercare (come stringhe)\n",
    "numeri_da_cercare_str = ['76', '185', '75', '184', '80', '81', '82', '187', '188', '189', '77', '78', '79', '186', '191', '88', '89', '90', '91', '192', '87', '83', '84', '85', '86', '190', '92', '93', '94', '95', '193', '96', '194', '98', '196', '97', '195', '61', '167', '58', '59', '60', '165', '166', '63', '64', '65', '168', '169', '62', '66', '170', '57', '68', '173', '174', '175', '176', '180', '69', '70', '71', '177', '178', '179', '67', '171', '172', '74', '183', '72', '73', '181', '182', '31', '132', '32', '33', '34', '133', '134', '135', '136', '29', '30', '131', '39', '141', '35', '36', '37', '38', '137', '138', '139', '140']\n",
    "\n",
    "# Lista per memorizzare i nomi delle colonne da mantenere\n",
    "colonne_da_mantenere = ['participant_id', 'Sex_F', 'ADHD_Outcome']\n",
    "\n",
    "# Itera sui nomi delle colonne di connettivitÃ \n",
    "colonne_connettivita = [col for col in train_final_connett.columns if col not in ['participant_id', 'Sex_F', 'ADHD_Outcome']]\n",
    "\n",
    "for col in colonne_connettivita:\n",
    "    for numero_str in numeri_da_cercare_str:\n",
    "        # Cerchiamo il numero come sottostringa intera, evitando '10', '22', ecc.\n",
    "        if numero_str in col:\n",
    "            try:\n",
    "                # Tentiamo di estrarre la parte prima e dopo il numero trovato\n",
    "                index = col.find(numero_str)\n",
    "                parte_prima = col[:index]\n",
    "                parte_dopo = col[index + len(numero_str):]\n",
    "\n",
    "                # Verifichiamo che il numero trovato sia \"intero\", ovvero delimitato da non-cifre o inizio/fine stringa\n",
    "                if (not parte_prima or not parte_prima[-1].isdigit()) and (not parte_dopo or not parte_dopo[0].isdigit()):\n",
    "                    colonne_da_mantenere.append(col)\n",
    "                    break # Se troviamo il numero intero, manteniamo la colonna e passiamo alla successiva\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "# Rimuovi i duplicati\n",
    "colonne_da_mantenere = list(set(colonne_da_mantenere))\n",
    "\n",
    "# Crea il DataFrame filtrato\n",
    "train_connett_manual = train_final_connett[colonne_da_mantenere]\n",
    "train_final_connett = train_connett_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "128b6353",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:18:00.037181Z",
     "iopub.status.busy": "2025-07-02T14:18:00.036831Z",
     "iopub.status.idle": "2025-07-02T14:20:19.060501Z",
     "shell.execute_reply": "2025-07-02T14:20:19.059313Z"
    },
    "papermill": {
     "duration": 139.037229,
     "end_time": "2025-07-02T14:20:19.067739",
     "exception": false,
     "start_time": "2025-07-02T14:18:00.030510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RISULTATI F1-SCORE SESSO ===\n",
      "ðŸ“Š FS MANUALE + AUTOMATICA:\n",
      "   âž¤ F1-score medio: 0.6810\n",
      "   âž¤ Dev. standard: 0.0482\n",
      "\n",
      "ðŸ›  FS SOLO MANUALE:\n",
      "   âž¤ F1-score medio: 0.5883\n",
      "   âž¤ Dev. standard: 0.0697\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# ========== PRIMA: MANUALE + AUTOMATICA ==========\n",
    "\n",
    "# Manuale\n",
    "numeri_da_cercare_str = ['76', '185', '75', '184', '80', '81', '82', '187', '188', '189', '77', '78', '79', '186', '191', '88', '89', '90', '91', '192', '87', '83', '84', '85', '86', '190', '92', '93', '94', '95', '193', '96', '194', '98', '196', '97', '195', '61', '167', '58', '59', '60', '165', '166', '63', '64', '65', '168', '169', '62', '66', '170', '57', '68', '173', '174', '175', '176', '180', '69', '70', '71', '177', '178', '179', '67', '171', '172', '74', '183', '72', '73', '181', '182', '31', '132', '32', '33', '34', '133', '134', '135', '136', '29', '30', '131', '39', '141', '35', '36', '37', '38', '137', '138', '139', '140']\n",
    "colonne_da_mantenere = ['participant_id', 'Sex_F', 'ADHD_Outcome']\n",
    "colonne_connettivita = [col for col in train_final_connett.columns if col not in colonne_da_mantenere]\n",
    "\n",
    "for col in colonne_connettivita:\n",
    "    for numero_str in numeri_da_cercare_str:\n",
    "        if numero_str in col:\n",
    "            index = col.find(numero_str)\n",
    "            parte_prima = col[:index]\n",
    "            parte_dopo = col[index + len(numero_str):]\n",
    "            if (not parte_prima or not parte_prima[-1].isdigit()) and (not parte_dopo or not parte_dopo[0].isdigit()):\n",
    "                colonne_da_mantenere.append(col)\n",
    "                break\n",
    "\n",
    "colonne_da_mantenere = list(set(colonne_da_mantenere))\n",
    "train_connett_manual = train_final_connett[colonne_da_mantenere]\n",
    "\n",
    "# Automatica\n",
    "y_sex = train_connett_manual['Sex_F'].astype(int)\n",
    "X_sex = train_connett_manual.drop(columns=['participant_id', 'Sex_F'])\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif, k=4000)\n",
    "X_selected = selector.fit_transform(X_sex, y_sex)\n",
    "selected_features = X_sex.columns[selector.get_support()]\n",
    "\n",
    "train_final_connett_auto = pd.concat(\n",
    "    [train_connett_manual[['participant_id', 'Sex_F', 'ADHD_Outcome']], X_sex[selected_features]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Modello SVM - FS AUTOMATICA + MANUALE\n",
    "X = train_final_connett_auto.drop(columns=['participant_id', 'Sex_F'])\n",
    "y = train_final_connett_auto['Sex_F'].astype(int)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "f1_scores_sex_auto = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    model = SVC(kernel='linear', class_weight='balanced', random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    f1_scores_sex_auto.append(f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# ========== ORA: SOLO MANUALE ==========\n",
    "\n",
    "train_final_connett_manu = train_connett_manual.copy()  # giÃ  filtrato manualmente\n",
    "\n",
    "# Modello SVM - SOLO FS MANUALE\n",
    "X = train_final_connett_manu.drop(columns=['participant_id', 'Sex_F'])\n",
    "y = train_final_connett_manu['Sex_F'].astype(int)\n",
    "\n",
    "f1_scores_sex_manu = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    model = SVC(kernel='linear', class_weight='balanced', random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    f1_scores_sex_manu.append(f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# ========== METRICHE ==========\n",
    "\n",
    "print(\"\\n=== RISULTATI F1-SCORE SESSO ===\")\n",
    "print(\"ðŸ“Š FS MANUALE + AUTOMATICA:\")\n",
    "print(f\"   âž¤ F1-score medio: {np.mean(f1_scores_sex_auto):.4f}\")\n",
    "print(f\"   âž¤ Dev. standard: {np.std(f1_scores_sex_auto):.4f}\")\n",
    "\n",
    "print(\"\\nðŸ›  FS SOLO MANUALE:\")\n",
    "print(f\"   âž¤ F1-score medio: {np.mean(f1_scores_sex_manu):.4f}\")\n",
    "print(f\"   âž¤ Dev. standard: {np.std(f1_scores_sex_manu):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f0f289a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:20:19.085103Z",
     "iopub.status.busy": "2025-07-02T14:20:19.084743Z",
     "iopub.status.idle": "2025-07-02T14:20:19.106079Z",
     "shell.execute_reply": "2025-07-02T14:20:19.105220Z"
    },
    "papermill": {
     "duration": 0.032109,
     "end_time": "2025-07-02T14:20:19.107994",
     "exception": false,
     "start_time": "2025-07-02T14:20:19.075885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'tesi_4.4_SVC_sex_manuale.csv' salvato con successo!\n",
      "File 'tesi_4.4_SVC_sex_mista.csv' salvato con successo!\n",
      "['tesi_4.4_SVC_sex_mista.csv', '__notebook__.ipynb', 'tesi_4.4_SVC_sex_manuale.csv']\n"
     ]
    }
   ],
   "source": [
    "f1_scores_sex_manu = pd.DataFrame(f1_scores_sex_manu, columns=[\"F1_sex_score\"])\n",
    "f1_scores_sex_manu.to_csv('tesi_4.4_SVC_sex_manuale.csv', index=False)\n",
    "print(\"File 'tesi_4.4_SVC_sex_manuale.csv' salvato con successo!\")\n",
    "f1_scores_sex_manu.head()\n",
    "\n",
    "f1_scores_sex_auto = pd.DataFrame(f1_scores_sex_auto, columns=[\"F1_sex_score\"])\n",
    "f1_scores_sex_auto.to_csv('tesi_4.4_SVC_sex_mista.csv', index=False)\n",
    "print(\"File 'tesi_4.4_SVC_sex_mista.csv' salvato con successo!\")\n",
    "f1_scores_sex_auto.head()\n",
    "\n",
    "\n",
    "import os\n",
    "print(os.listdir('.')) # Mostra i file nella directory corrente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5364634c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:20:19.126381Z",
     "iopub.status.busy": "2025-07-02T14:20:19.125594Z",
     "iopub.status.idle": "2025-07-02T14:20:19.144106Z",
     "shell.execute_reply": "2025-07-02T14:20:19.143240Z"
    },
    "papermill": {
     "duration": 0.029709,
     "end_time": "2025-07-02T14:20:19.146547",
     "exception": false,
     "start_time": "2025-07-02T14:20:19.116838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/widsdatathon2025/SAMPLE_SUBMISSION.xlsx\n",
      "/kaggle/input/widsdatathon2025/Data Dictionary.xlsx\n",
      "/kaggle/input/widsdatathon2025/TRAIN_OLD/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv\n",
      "/kaggle/input/widsdatathon2025/TRAIN_OLD/TRAINING_SOLUTIONS.xlsx\n",
      "/kaggle/input/widsdatathon2025/TRAIN_OLD/TRAIN_CATEGORICAL_METADATA.xlsx\n",
      "/kaggle/input/widsdatathon2025/TRAIN_OLD/TRAIN_QUANTITATIVE_METADATA.xlsx\n",
      "/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAINING_SOLUTIONS.xlsx\n",
      "/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv\n",
      "/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAIN_CATEGORICAL_METADATA_new.xlsx\n",
      "/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAIN_QUANTITATIVE_METADATA_new.xlsx\n",
      "/kaggle/input/widsdatathon2025/TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv\n",
      "/kaggle/input/widsdatathon2025/TEST/TEST_CATEGORICAL.xlsx\n",
      "/kaggle/input/widsdatathon2025/TEST/TEST_QUANTITATIVE_METADATA.xlsx\n"
     ]
    }
   ],
   "source": [
    "#This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from scipy.stats import zscore, pearsonr, uniform\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RandomizedSearchCV\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbdb409c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:20:19.165340Z",
     "iopub.status.busy": "2025-07-02T14:20:19.164898Z",
     "iopub.status.idle": "2025-07-02T14:20:36.694499Z",
     "shell.execute_reply": "2025-07-02T14:20:36.692988Z"
    },
    "papermill": {
     "duration": 17.542684,
     "end_time": "2025-07-02T14:20:36.697617",
     "exception": false,
     "start_time": "2025-07-02T14:20:19.154933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/739009659.py:13: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  train_encoded = train_encoded.applymap(lambda x: 1 if x is True else (0 if x is False else x))\n",
      "/tmp/ipykernel_13/739009659.py:40: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  test_encoded = test_encoded.applymap(lambda x: 1 if x is True else (0 if x is False else x))\n"
     ]
    }
   ],
   "source": [
    "#Caricamento del dataset di train\n",
    "train_cat = pd.read_excel (\"/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAIN_CATEGORICAL_METADATA_new.xlsx\")\n",
    "train_quant = pd.read_excel(\"/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAIN_QUANTITATIVE_METADATA_new.xlsx\")\n",
    "train_fmri = pd.read_csv(\"/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv\")\n",
    "train_sol = pd.read_excel(\"/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAINING_SOLUTIONS.xlsx\")\n",
    "\n",
    "#One hot encoding dei dati categorici\n",
    "for col in train_cat.select_dtypes(include='int').columns:\n",
    "    train_cat[col] = train_cat[col].astype('category')\n",
    "\n",
    "columns_to_encode = train_cat.columns[1:].tolist()\n",
    "train_encoded = pd.get_dummies(train_cat[columns_to_encode], drop_first=True)\n",
    "train_encoded = train_encoded.applymap(lambda x: 1 if x is True else (0 if x is False else x))\n",
    "\n",
    "cat_train_final = pd.concat([train_cat.drop(columns=columns_to_encode), train_encoded], axis=1)\n",
    "cat_train_final.head()\n",
    "\n",
    "\n",
    "#Merging dei dati categorici (dopo aver fatto l'encoding) con i dati quantitativi e le soluzioni, per ottenere il dataset dei dati demografici\n",
    "train_demo = pd.merge(cat_train_final, train_quant, on = 'participant_id')\n",
    "train_final_demo = pd.merge(train_demo, train_sol, on = 'participant_id')\n",
    "train_final_demo.head()\n",
    "\n",
    "#Merging dei dati fmri le soluzioni, per ottenere il dataset dei dati di connettivitÃ \n",
    "train_final_connett = pd.merge(train_fmri, train_sol, on = 'participant_id')\n",
    "train_final_connett.head()\n",
    "\n",
    "\n",
    "#Caricamento del dataset di test\n",
    "test_cat = pd.read_excel(\"/kaggle/input/widsdatathon2025/TEST/TEST_CATEGORICAL.xlsx\")\n",
    "test_quant = pd.read_excel(\"/kaggle/input/widsdatathon2025/TEST/TEST_QUANTITATIVE_METADATA.xlsx\")\n",
    "test_fmri = pd.read_csv(\"/kaggle/input/widsdatathon2025/TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv\")\n",
    "\n",
    "#One hot encoding dei dati categorici\n",
    "for col in test_cat.select_dtypes(include='int').columns:\n",
    "    test_cat[col] = test_cat[col].astype('category')\n",
    "\n",
    "columns_to_encode = test_cat.columns[1:].tolist()\n",
    "test_encoded = pd.get_dummies(test_cat[columns_to_encode], drop_first=True)\n",
    "test_encoded = test_encoded.applymap(lambda x: 1 if x is True else (0 if x is False else x))\n",
    "\n",
    "cat_test_final = pd.concat([test_cat.drop(columns=columns_to_encode), test_encoded], axis=1)\n",
    "cat_test_final.head()\n",
    "\n",
    "\n",
    "#Merging dei dati categorici (dopo aver fatto l'encoding) con i dati quantitativi, per ottenere il dataset dei dati demografici\n",
    "test_final_demo = pd.merge(cat_test_final, test_quant, on = 'participant_id')\n",
    "test_final_demo.head()\n",
    "\n",
    "#Cambio il nome dei dati fmri per ottenere il dataset dei dati di connettivitÃ \n",
    "test_final_connett = test_fmri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e40f1d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:20:36.710985Z",
     "iopub.status.busy": "2025-07-02T14:20:36.710085Z",
     "iopub.status.idle": "2025-07-02T14:20:36.776293Z",
     "shell.execute_reply": "2025-07-02T14:20:36.774493Z"
    },
    "papermill": {
     "duration": 0.075169,
     "end_time": "2025-07-02T14:20:36.778597",
     "exception": false,
     "start_time": "2025-07-02T14:20:36.703428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant_id                        0\n",
      "PreInt_Demos_Fam_Child_Ethnicity     43\n",
      "PreInt_Demos_Fam_Child_Race          54\n",
      "MRI_Track_Scan_Location               3\n",
      "Barratt_Barratt_P1_Edu               15\n",
      "Barratt_Barratt_P1_Occ               31\n",
      "Barratt_Barratt_P2_Edu              198\n",
      "Barratt_Barratt_P2_Occ              222\n",
      "Basic_Demos_Enroll_Year_2016          0\n",
      "Basic_Demos_Enroll_Year_2017          0\n",
      "Basic_Demos_Enroll_Year_2018          0\n",
      "Basic_Demos_Enroll_Year_2019          0\n",
      "Basic_Demos_Enroll_Year_2020          0\n",
      "Basic_Demos_Study_Site_2              0\n",
      "Basic_Demos_Study_Site_3              0\n",
      "Basic_Demos_Study_Site_4              0\n",
      "EHQ_EHQ_Total                        13\n",
      "ColorVision_CV_Score                 23\n",
      "APQ_P_APQ_P_CP                       12\n",
      "APQ_P_APQ_P_ID                       12\n",
      "APQ_P_APQ_P_INV                      12\n",
      "APQ_P_APQ_P_OPD                      12\n",
      "APQ_P_APQ_P_PM                       12\n",
      "APQ_P_APQ_P_PP                       12\n",
      "SDQ_SDQ_Conduct_Problems              9\n",
      "SDQ_SDQ_Difficulties_Total            9\n",
      "SDQ_SDQ_Emotional_Problems            9\n",
      "SDQ_SDQ_Externalizing                 9\n",
      "SDQ_SDQ_Generating_Impact             9\n",
      "SDQ_SDQ_Hyperactivity                 9\n",
      "SDQ_SDQ_Internalizing                 9\n",
      "SDQ_SDQ_Peer_Problems                 9\n",
      "SDQ_SDQ_Prosocial                     9\n",
      "MRI_Track_Age_at_Scan               360\n",
      "ADHD_Outcome                          0\n",
      "Sex_F                                 0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "participant_id                      0\n",
      "PreInt_Demos_Fam_Child_Ethnicity    0\n",
      "PreInt_Demos_Fam_Child_Race         0\n",
      "MRI_Track_Scan_Location             0\n",
      "Barratt_Barratt_P1_Edu              0\n",
      "Barratt_Barratt_P1_Occ              0\n",
      "Barratt_Barratt_P2_Edu              0\n",
      "Barratt_Barratt_P2_Occ              0\n",
      "Basic_Demos_Enroll_Year_2016        0\n",
      "Basic_Demos_Enroll_Year_2017        0\n",
      "Basic_Demos_Enroll_Year_2018        0\n",
      "Basic_Demos_Enroll_Year_2019        0\n",
      "Basic_Demos_Enroll_Year_2020        0\n",
      "Basic_Demos_Study_Site_2            0\n",
      "Basic_Demos_Study_Site_3            0\n",
      "Basic_Demos_Study_Site_4            0\n",
      "EHQ_EHQ_Total                       0\n",
      "ColorVision_CV_Score                0\n",
      "APQ_P_APQ_P_CP                      0\n",
      "APQ_P_APQ_P_ID                      0\n",
      "APQ_P_APQ_P_INV                     0\n",
      "APQ_P_APQ_P_OPD                     0\n",
      "APQ_P_APQ_P_PM                      0\n",
      "APQ_P_APQ_P_PP                      0\n",
      "SDQ_SDQ_Conduct_Problems            0\n",
      "SDQ_SDQ_Difficulties_Total          0\n",
      "SDQ_SDQ_Emotional_Problems          0\n",
      "SDQ_SDQ_Externalizing               0\n",
      "SDQ_SDQ_Generating_Impact           0\n",
      "SDQ_SDQ_Hyperactivity               0\n",
      "SDQ_SDQ_Internalizing               0\n",
      "SDQ_SDQ_Peer_Problems               0\n",
      "SDQ_SDQ_Prosocial                   0\n",
      "MRI_Track_Age_at_Scan               0\n",
      "ADHD_Outcome                        0\n",
      "Sex_F                               0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "0\n",
      "participant_id                       0\n",
      "PreInt_Demos_Fam_Child_Ethnicity     3\n",
      "PreInt_Demos_Fam_Child_Race          6\n",
      "Barratt_Barratt_P1_Edu               1\n",
      "Barratt_Barratt_P1_Occ               1\n",
      "Barratt_Barratt_P2_Edu              36\n",
      "Barratt_Barratt_P2_Occ              42\n",
      "Basic_Demos_Enroll_Year_2020         0\n",
      "Basic_Demos_Enroll_Year_2021         0\n",
      "Basic_Demos_Enroll_Year_2022         0\n",
      "Basic_Demos_Enroll_Year_2023         0\n",
      "Basic_Demos_Study_Site_5             0\n",
      "MRI_Track_Scan_Location_4            0\n",
      "EHQ_EHQ_Total                        1\n",
      "ColorVision_CV_Score                 9\n",
      "APQ_P_APQ_P_CP                      15\n",
      "APQ_P_APQ_P_ID                      15\n",
      "APQ_P_APQ_P_INV                     15\n",
      "APQ_P_APQ_P_OPD                     15\n",
      "APQ_P_APQ_P_PM                      15\n",
      "APQ_P_APQ_P_PP                      15\n",
      "SDQ_SDQ_Conduct_Problems            30\n",
      "SDQ_SDQ_Difficulties_Total          30\n",
      "SDQ_SDQ_Emotional_Problems          30\n",
      "SDQ_SDQ_Externalizing               30\n",
      "SDQ_SDQ_Generating_Impact           30\n",
      "SDQ_SDQ_Hyperactivity               30\n",
      "SDQ_SDQ_Internalizing               30\n",
      "SDQ_SDQ_Peer_Problems               30\n",
      "SDQ_SDQ_Prosocial                   30\n",
      "MRI_Track_Age_at_Scan                0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "participant_id                      0\n",
      "PreInt_Demos_Fam_Child_Ethnicity    0\n",
      "PreInt_Demos_Fam_Child_Race         0\n",
      "Barratt_Barratt_P1_Edu              0\n",
      "Barratt_Barratt_P1_Occ              0\n",
      "Barratt_Barratt_P2_Edu              0\n",
      "Barratt_Barratt_P2_Occ              0\n",
      "Basic_Demos_Enroll_Year_2020        0\n",
      "Basic_Demos_Enroll_Year_2021        0\n",
      "Basic_Demos_Enroll_Year_2022        0\n",
      "Basic_Demos_Enroll_Year_2023        0\n",
      "Basic_Demos_Study_Site_5            0\n",
      "MRI_Track_Scan_Location_4           0\n",
      "EHQ_EHQ_Total                       0\n",
      "ColorVision_CV_Score                0\n",
      "APQ_P_APQ_P_CP                      0\n",
      "APQ_P_APQ_P_ID                      0\n",
      "APQ_P_APQ_P_INV                     0\n",
      "APQ_P_APQ_P_OPD                     0\n",
      "APQ_P_APQ_P_PM                      0\n",
      "APQ_P_APQ_P_PP                      0\n",
      "SDQ_SDQ_Conduct_Problems            0\n",
      "SDQ_SDQ_Difficulties_Total          0\n",
      "SDQ_SDQ_Emotional_Problems          0\n",
      "SDQ_SDQ_Externalizing               0\n",
      "SDQ_SDQ_Generating_Impact           0\n",
      "SDQ_SDQ_Hyperactivity               0\n",
      "SDQ_SDQ_Internalizing               0\n",
      "SDQ_SDQ_Peer_Problems               0\n",
      "SDQ_SDQ_Prosocial                   0\n",
      "MRI_Track_Age_at_Scan               0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Controllo quanti valori nulli ci sono nel dataset di train\n",
    "print(train_final_demo.isna().sum())\n",
    "\n",
    "#Sostituisco i valori mancanti delle variabili categoriche con la moda\n",
    "train_final_demo['PreInt_Demos_Fam_Child_Ethnicity'] = train_final_demo['PreInt_Demos_Fam_Child_Ethnicity'].fillna(train_final_demo['PreInt_Demos_Fam_Child_Ethnicity'].mode()[0])\n",
    "train_final_demo['PreInt_Demos_Fam_Child_Race'] = train_final_demo['PreInt_Demos_Fam_Child_Race'].fillna(train_final_demo['PreInt_Demos_Fam_Child_Race'].mode()[0])\n",
    "train_final_demo['MRI_Track_Scan_Location'] = train_final_demo['MRI_Track_Scan_Location'].fillna(train_final_demo['MRI_Track_Scan_Location'].mode()[0])\n",
    "train_final_demo['Barratt_Barratt_P1_Edu'] = train_final_demo['Barratt_Barratt_P1_Edu'].fillna(train_final_demo['Barratt_Barratt_P1_Edu'].mode()[0])\n",
    "train_final_demo['Barratt_Barratt_P1_Occ'] = train_final_demo['Barratt_Barratt_P1_Occ'].fillna(train_final_demo['Barratt_Barratt_P1_Occ'].mode()[0])\n",
    "train_final_demo['Barratt_Barratt_P2_Edu'] = train_final_demo['Barratt_Barratt_P2_Edu'].fillna(train_final_demo['Barratt_Barratt_P2_Edu'].mode()[0])\n",
    "train_final_demo['Barratt_Barratt_P2_Occ'] = train_final_demo['Barratt_Barratt_P2_Occ'].fillna(train_final_demo['Barratt_Barratt_P2_Occ'].mode()[0])\n",
    "\n",
    "#Sostituisco i valori mancanti delle variabili quantitative con la media\n",
    "train_final_demo.fillna({'EHQ_EHQ_Total':train_final_demo['EHQ_EHQ_Total'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'ColorVision_CV_Score':train_final_demo['ColorVision_CV_Score'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'APQ_P_APQ_P_CP':train_final_demo['APQ_P_APQ_P_CP'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'APQ_P_APQ_P_ID':train_final_demo['APQ_P_APQ_P_ID'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'APQ_P_APQ_P_INV':train_final_demo['APQ_P_APQ_P_INV'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'APQ_P_APQ_P_OPD':train_final_demo['APQ_P_APQ_P_OPD'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'APQ_P_APQ_P_PM':train_final_demo['APQ_P_APQ_P_PM'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'APQ_P_APQ_P_PP':train_final_demo['APQ_P_APQ_P_PP'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'SDQ_SDQ_Conduct_Problems':train_final_demo['SDQ_SDQ_Conduct_Problems'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'SDQ_SDQ_Difficulties_Total':train_final_demo['SDQ_SDQ_Difficulties_Total'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'SDQ_SDQ_Emotional_Problems':train_final_demo['SDQ_SDQ_Emotional_Problems'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'SDQ_SDQ_Externalizing':train_final_demo['SDQ_SDQ_Externalizing'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'SDQ_SDQ_Generating_Impact':train_final_demo['SDQ_SDQ_Generating_Impact'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'SDQ_SDQ_Hyperactivity':train_final_demo['SDQ_SDQ_Hyperactivity'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'SDQ_SDQ_Internalizing':train_final_demo['SDQ_SDQ_Internalizing'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'SDQ_SDQ_Peer_Problems':train_final_demo['SDQ_SDQ_Peer_Problems'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'SDQ_SDQ_Prosocial':train_final_demo['SDQ_SDQ_Prosocial'].mean()}, inplace = True)\n",
    "train_final_demo.fillna({'MRI_Track_Age_at_Scan':train_final_demo['MRI_Track_Age_at_Scan'].mean()}, inplace = True)\n",
    "\n",
    "#Ora non ci sono piÃ¹ NaN values\n",
    "print('\\n\\n')\n",
    "print(train_final_demo.isna().sum())\n",
    "print('\\n')\n",
    "print(train_final_demo.isna().sum().sum())\n",
    "\n",
    "\n",
    "#Controllo quanti valori nulli ci sono nel dataset di test\n",
    "print(test_final_demo.isna().sum())\n",
    "\n",
    "#Sostituisco i valori mancanti delle variabili categoriche con la moda\n",
    "test_final_demo['PreInt_Demos_Fam_Child_Ethnicity'] = test_final_demo['PreInt_Demos_Fam_Child_Ethnicity'].fillna(test_final_demo['PreInt_Demos_Fam_Child_Ethnicity'].mode()[0])\n",
    "test_final_demo['PreInt_Demos_Fam_Child_Race'] = test_final_demo['PreInt_Demos_Fam_Child_Race'].fillna(test_final_demo['PreInt_Demos_Fam_Child_Race'].mode()[0])\n",
    "test_final_demo['Barratt_Barratt_P1_Edu'] = test_final_demo['Barratt_Barratt_P1_Edu'].fillna(test_final_demo['Barratt_Barratt_P1_Edu'].mode()[0])\n",
    "test_final_demo['Barratt_Barratt_P1_Occ'] = test_final_demo['Barratt_Barratt_P1_Occ'].fillna(test_final_demo['Barratt_Barratt_P1_Occ'].mode()[0])\n",
    "test_final_demo['Barratt_Barratt_P2_Edu'] = test_final_demo['Barratt_Barratt_P2_Edu'].fillna(test_final_demo['Barratt_Barratt_P2_Edu'].mode()[0])\n",
    "test_final_demo['Barratt_Barratt_P2_Occ'] = test_final_demo['Barratt_Barratt_P2_Occ'].fillna(test_final_demo['Barratt_Barratt_P2_Occ'].mode()[0])\n",
    "\n",
    "# Sostituisco i valori mancanti delle variabili quantitative con la media\n",
    "test_final_demo.fillna({'EHQ_EHQ_Total': test_final_demo['EHQ_EHQ_Total'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'ColorVision_CV_Score': test_final_demo['ColorVision_CV_Score'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'APQ_P_APQ_P_CP': test_final_demo['APQ_P_APQ_P_CP'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'APQ_P_APQ_P_ID': test_final_demo['APQ_P_APQ_P_ID'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'APQ_P_APQ_P_INV': test_final_demo['APQ_P_APQ_P_INV'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'APQ_P_APQ_P_OPD': test_final_demo['APQ_P_APQ_P_OPD'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'APQ_P_APQ_P_PM': test_final_demo['APQ_P_APQ_P_PM'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'APQ_P_APQ_P_PP': test_final_demo['APQ_P_APQ_P_PP'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'SDQ_SDQ_Conduct_Problems': test_final_demo['SDQ_SDQ_Conduct_Problems'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'SDQ_SDQ_Difficulties_Total': test_final_demo['SDQ_SDQ_Difficulties_Total'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'SDQ_SDQ_Emotional_Problems': test_final_demo['SDQ_SDQ_Emotional_Problems'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'SDQ_SDQ_Externalizing': test_final_demo['SDQ_SDQ_Externalizing'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'SDQ_SDQ_Generating_Impact': test_final_demo['SDQ_SDQ_Generating_Impact'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'SDQ_SDQ_Hyperactivity': test_final_demo['SDQ_SDQ_Hyperactivity'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'SDQ_SDQ_Internalizing': test_final_demo['SDQ_SDQ_Internalizing'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'SDQ_SDQ_Peer_Problems': test_final_demo['SDQ_SDQ_Peer_Problems'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'SDQ_SDQ_Prosocial': test_final_demo['SDQ_SDQ_Prosocial'].mean()}, inplace=True)\n",
    "test_final_demo.fillna({'MRI_Track_Age_at_Scan': test_final_demo['MRI_Track_Age_at_Scan'].mean()}, inplace=True)\n",
    "\n",
    "\n",
    "#Ora non ci sono piÃ¹ NaN values\n",
    "print('\\n\\n')\n",
    "print(test_final_demo.isna().sum())\n",
    "print('\\n')\n",
    "print(test_final_demo.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c0594ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:20:36.793570Z",
     "iopub.status.busy": "2025-07-02T14:20:36.793113Z",
     "iopub.status.idle": "2025-07-02T14:20:52.061483Z",
     "shell.execute_reply": "2025-07-02T14:20:52.059552Z"
    },
    "papermill": {
     "duration": 15.27858,
     "end_time": "2025-07-02T14:20:52.063658",
     "exception": false,
     "start_time": "2025-07-02T14:20:36.785078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¢ Numero di feature iniziali (INCLUSI ID e target): 36\n",
      "ðŸ§¹ Numero di feature dopo la selezione manuale: 32\n",
      "ðŸ” Numero di feature selezionate automaticamente (SelectKBest): 26\n",
      "âš™ï¸ Numero totale di colonne finali (con ID e target): 28\n",
      "\n",
      "ðŸ“Œ Feature selezionate: ['PreInt_Demos_Fam_Child_Ethnicity', 'PreInt_Demos_Fam_Child_Race', 'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Occ', 'Basic_Demos_Enroll_Year_2016', 'Basic_Demos_Enroll_Year_2017', 'Basic_Demos_Enroll_Year_2018', 'Basic_Demos_Enroll_Year_2019', 'Basic_Demos_Enroll_Year_2020', 'EHQ_EHQ_Total', 'ColorVision_CV_Score', 'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial', 'Sex_F']\n",
      "\n",
      "=== Fold 1 ===\n",
      "  Dimensione X_train: (1091, 26)\n",
      "  Dimensione X_test: (122, 26)\n",
      "  Dimensione y_train: (1091,)\n",
      "  Dimensione y_test: (122,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 0 0 1 0]\n",
      "  Valori reali y_test (prime 5): [1 0 1 1 1]\n",
      "\n",
      "=== Fold 2 ===\n",
      "  Dimensione X_train: (1091, 26)\n",
      "  Dimensione X_test: (122, 26)\n",
      "  Dimensione y_train: (1091,)\n",
      "  Dimensione y_test: (122,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 1 1 0 1]\n",
      "  Valori reali y_test (prime 5): [1 1 0 0 1]\n",
      "\n",
      "=== Fold 3 ===\n",
      "  Dimensione X_train: (1091, 26)\n",
      "  Dimensione X_test: (122, 26)\n",
      "  Dimensione y_train: (1091,)\n",
      "  Dimensione y_test: (122,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 1 1 0 1]\n",
      "  Valori reali y_test (prime 5): [1 0 1 0 1]\n",
      "\n",
      "=== Fold 4 ===\n",
      "  Dimensione X_train: (1092, 26)\n",
      "  Dimensione X_test: (121, 26)\n",
      "  Dimensione y_train: (1092,)\n",
      "  Dimensione y_test: (121,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 1 1 1 0]\n",
      "  Valori reali y_test (prime 5): [1 1 1 1 0]\n",
      "\n",
      "=== Fold 5 ===\n",
      "  Dimensione X_train: (1092, 26)\n",
      "  Dimensione X_test: (121, 26)\n",
      "  Dimensione y_train: (1092,)\n",
      "  Dimensione y_test: (121,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 1 0 1 1]\n",
      "  Valori reali y_test (prime 5): [0 1 0 0 1]\n",
      "\n",
      "=== Fold 6 ===\n",
      "  Dimensione X_train: (1092, 26)\n",
      "  Dimensione X_test: (121, 26)\n",
      "  Dimensione y_train: (1092,)\n",
      "  Dimensione y_test: (121,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 0 1 0 1]\n",
      "  Valori reali y_test (prime 5): [1 1 1 1 1]\n",
      "\n",
      "=== Fold 7 ===\n",
      "  Dimensione X_train: (1092, 26)\n",
      "  Dimensione X_test: (121, 26)\n",
      "  Dimensione y_train: (1092,)\n",
      "  Dimensione y_test: (121,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 1 0 1 0]\n",
      "  Valori reali y_test (prime 5): [1 1 0 0 0]\n",
      "\n",
      "=== Fold 8 ===\n",
      "  Dimensione X_train: (1092, 26)\n",
      "  Dimensione X_test: (121, 26)\n",
      "  Dimensione y_train: (1092,)\n",
      "  Dimensione y_test: (121,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 0 1 1 1]\n",
      "  Valori reali y_test (prime 5): [1 0 1 1 1]\n",
      "\n",
      "=== Fold 9 ===\n",
      "  Dimensione X_train: (1092, 26)\n",
      "  Dimensione X_test: (121, 26)\n",
      "  Dimensione y_train: (1092,)\n",
      "  Dimensione y_test: (121,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 1 1 1 1]\n",
      "  Valori reali y_test (prime 5): [1 0 1 1 1]\n",
      "\n",
      "=== Fold 10 ===\n",
      "  Dimensione X_train: (1092, 26)\n",
      "  Dimensione X_test: (121, 26)\n",
      "  Dimensione y_train: (1092,)\n",
      "  Dimensione y_test: (121,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 1 1 1 1]\n",
      "  Valori reali y_test (prime 5): [1 0 1 1 0]\n",
      "\n",
      "=== Media delle metriche su 10 fold ===\n",
      "F1-score medio ADHD_Outcome: 0.8516\n",
      "Deviazione standard F1-score ADHD_Outcome: 0.0247\n"
     ]
    }
   ],
   "source": [
    "# === FEATURE SELECTION MANUALE PER DATI DEMOGRAFICI ===\n",
    "# DATI DI TRAIN\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "\n",
    "# Lista delle features (colonne) che vuoi eliminare\n",
    "features_da_eliminare = [\"Basic_Demos_Study_Site_2\", \"Basic_Demos_Study_Site_3\", \"Basic_Demos_Study_Site_4\", \"MRI_Track_Scan_Location\"]\n",
    "\n",
    "# Salva numero di feature iniziali (INCLUDENDO ID e target)\n",
    "n_feature_iniziali = train_final_demo.shape[1]\n",
    "\n",
    "# Elimina le features specificate dal DataFrame\n",
    "train_final_demo = train_final_demo.drop(columns=features_da_eliminare, errors='ignore')\n",
    "\n",
    "# Salva numero di feature dopo rimozione manuale\n",
    "n_feature_post_manuale = train_final_demo.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "# === FEATURE SELECTION AUTOMATICA PER DATI DEMOGRAFICI (SelectKBest) ===\n",
    "# DATI DI TRAIN\n",
    "\n",
    "# Colonne da mantenere sempre nel dataset finale\n",
    "colonne_da_aggiungere = ['participant_id','ADHD_Outcome']\n",
    "colonne_da_aggiungere_presenti = [col for col in colonne_da_aggiungere if col in train_final_demo.columns]\n",
    "\n",
    "# Seleziona solo le colonne numeriche (int o float)\n",
    "train_numeriche = train_final_demo.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Escludi le colonne da mantenere\n",
    "feature_data = train_numeriche.drop(columns=[col for col in colonne_da_aggiungere_presenti if col in train_numeriche.columns], errors='ignore')\n",
    "\n",
    "# Estrai il target per la selezione automatica\n",
    "y_kbest = train_final_demo['ADHD_Outcome'].astype(int)\n",
    "\n",
    "# Applica SelectKBest\n",
    "k = 26\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "X_selected = selector.fit_transform(feature_data, y_kbest)\n",
    "\n",
    "# Ottieni i nomi delle feature selezionate\n",
    "feature_mask = selector.get_support()\n",
    "selected_features = feature_data.columns[feature_mask]\n",
    "\n",
    "# Costruisci il nuovo DataFrame\n",
    "train_final_demo_selected = pd.concat(\n",
    "    [train_final_demo[colonne_da_aggiungere_presenti], feature_data[selected_features]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Output finale\n",
    "print(f\"ðŸ”¢ Numero di feature iniziali (INCLUSI ID e target): {n_feature_iniziali}\")\n",
    "print(f\"ðŸ§¹ Numero di feature dopo la selezione manuale: {n_feature_post_manuale}\")\n",
    "print(f\"ðŸ” Numero di feature selezionate automaticamente (SelectKBest): {len(selected_features)}\")\n",
    "print(f\"âš™ï¸ Numero totale di colonne finali (con ID e target): {train_final_demo_selected.shape[1]}\")\n",
    "print(\"\\nðŸ“Œ Feature selezionate:\", list(selected_features))\n",
    "\n",
    "\n",
    "# === MODELLAZIONE CON RANDOM FOREST (300 estimatori) PER ADHD USANDO DATI DEMOGRAFICI ===\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Features e target\n",
    "X = train_final_demo_selected.drop(columns=['participant_id', 'ADHD_Outcome'])\n",
    "y = train_final_demo_selected['ADHD_Outcome'].astype(int)\n",
    "\n",
    "# Cross-validation stratificata su ADHD_Outcome\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Liste per salvare i risultati di ogni fold\n",
    "acc_scores_adhd = []\n",
    "f1_scores_adhd = []\n",
    "\n",
    "# Cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    print(f\"  Dimensione X_train: {X_train.shape}\")\n",
    "    print(f\"  Dimensione X_test: {X_test.shape}\")\n",
    "    print(f\"  Dimensione y_train: {y_train.shape}\")\n",
    "    print(f\"  Dimensione y_test: {y_test.shape}\")\n",
    "    print(f\"  Valori unici in y_train: {np.unique(y_train)}\")\n",
    "    print(f\"  Valori unici in y_test: {np.unique(y_test)}\")\n",
    "\n",
    "    # === Standardizzazione === (facoltativa per Random Forest, ma la manteniamo per coerenza)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # === Modello Random Forest ===\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "    print(f\"  Predizioni y_pred (prime 5): {y_pred[:5]}\")\n",
    "    print(f\"  Valori reali y_test (prime 5): {y_test[:5].values}\")\n",
    "\n",
    "    # Metriche per questo fold\n",
    "    acc_scores_adhd.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores_adhd.append(f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# === RISULTATI FINALI ===\n",
    "print(\"\\n=== Media delle metriche su 10 fold ===\")\n",
    "print(f\"F1-score medio ADHD_Outcome: {np.mean(f1_scores_adhd):.4f}\")\n",
    "print(f\"Deviazione standard F1-score ADHD_Outcome: {np.std(f1_scores_adhd):.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7fa79da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:20:52.079998Z",
     "iopub.status.busy": "2025-07-02T14:20:52.079606Z",
     "iopub.status.idle": "2025-07-02T14:21:06.833083Z",
     "shell.execute_reply": "2025-07-02T14:21:06.831863Z"
    },
    "papermill": {
     "duration": 14.764583,
     "end_time": "2025-07-02T14:21:06.835146",
     "exception": false,
     "start_time": "2025-07-02T14:20:52.070563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "  Dimensione X_train: (1091, 30)\n",
      "  Dimensione X_test: (122, 30)\n",
      "  Dimensione y_train: (1091,)\n",
      "  Dimensione y_test: (122,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 0 0 1 0]\n",
      "  Valori reali y_test (prime 5): [1 0 1 1 1]\n",
      "\n",
      "=== Fold 2 ===\n",
      "  Dimensione X_train: (1091, 30)\n",
      "  Dimensione X_test: (122, 30)\n",
      "  Dimensione y_train: (1091,)\n",
      "  Dimensione y_test: (122,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 1 1 0 1]\n",
      "  Valori reali y_test (prime 5): [1 1 0 0 1]\n",
      "\n",
      "=== Fold 3 ===\n",
      "  Dimensione X_train: (1091, 30)\n",
      "  Dimensione X_test: (122, 30)\n",
      "  Dimensione y_train: (1091,)\n",
      "  Dimensione y_test: (122,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 1 1 0 1]\n",
      "  Valori reali y_test (prime 5): [1 0 1 0 1]\n",
      "\n",
      "=== Fold 4 ===\n",
      "  Dimensione X_train: (1092, 30)\n",
      "  Dimensione X_test: (121, 30)\n",
      "  Dimensione y_train: (1092,)\n",
      "  Dimensione y_test: (121,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 1 1 1 0]\n",
      "  Valori reali y_test (prime 5): [1 1 1 1 0]\n",
      "\n",
      "=== Fold 5 ===\n",
      "  Dimensione X_train: (1092, 30)\n",
      "  Dimensione X_test: (121, 30)\n",
      "  Dimensione y_train: (1092,)\n",
      "  Dimensione y_test: (121,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [0 1 0 1 1]\n",
      "  Valori reali y_test (prime 5): [0 1 0 0 1]\n",
      "\n",
      "=== Fold 6 ===\n",
      "  Dimensione X_train: (1092, 30)\n",
      "  Dimensione X_test: (121, 30)\n",
      "  Dimensione y_train: (1092,)\n",
      "  Dimensione y_test: (121,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 0 1 0 1]\n",
      "  Valori reali y_test (prime 5): [1 1 1 1 1]\n",
      "\n",
      "=== Fold 7 ===\n",
      "  Dimensione X_train: (1092, 30)\n",
      "  Dimensione X_test: (121, 30)\n",
      "  Dimensione y_train: (1092,)\n",
      "  Dimensione y_test: (121,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 1 0 1 0]\n",
      "  Valori reali y_test (prime 5): [1 1 0 0 0]\n",
      "\n",
      "=== Fold 8 ===\n",
      "  Dimensione X_train: (1092, 30)\n",
      "  Dimensione X_test: (121, 30)\n",
      "  Dimensione y_train: (1092,)\n",
      "  Dimensione y_test: (121,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 0 1 1 1]\n",
      "  Valori reali y_test (prime 5): [1 0 1 1 1]\n",
      "\n",
      "=== Fold 9 ===\n",
      "  Dimensione X_train: (1092, 30)\n",
      "  Dimensione X_test: (121, 30)\n",
      "  Dimensione y_train: (1092,)\n",
      "  Dimensione y_test: (121,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 1 1 1 1]\n",
      "  Valori reali y_test (prime 5): [1 0 1 1 1]\n",
      "\n",
      "=== Fold 10 ===\n",
      "  Dimensione X_train: (1092, 30)\n",
      "  Dimensione X_test: (121, 30)\n",
      "  Dimensione y_train: (1092,)\n",
      "  Dimensione y_test: (121,)\n",
      "  Valori unici in y_train: [0 1]\n",
      "  Valori unici in y_test: [0 1]\n",
      "  Predizioni y_pred (prime 5): [1 1 1 1 1]\n",
      "  Valori reali y_test (prime 5): [1 0 1 1 0]\n",
      "\n",
      "=== Media delle metriche su 10 fold ===\n",
      "F1-score medio ADHD_Outcome: 0.8566\n",
      "Deviazione standard F1-score ADHD_Outcome: 0.0288\n"
     ]
    }
   ],
   "source": [
    "# === FEATURE SELECTION MANUALE PER DATI DEMOGRAFICI ===\n",
    "# DATI DI TRAIN\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "\n",
    "# Lista delle features (colonne) che vuoi eliminare\n",
    "features_da_eliminare = [\"Basic_Demos_Study_Site_2\", \"Basic_Demos_Study_Site_3\", \"Basic_Demos_Study_Site_4\", \"MRI_Track_Scan_Location\"]\n",
    "\n",
    "# Salva numero di feature iniziali (INCLUDENDO ID e target)\n",
    "n_feature_iniziali = train_final_demo.shape[1]\n",
    "\n",
    "# Elimina le features specificate dal DataFrame\n",
    "train_final_demo_selected = train_final_demo.drop(columns=features_da_eliminare, errors='ignore')\n",
    "\n",
    "# Salva numero di feature dopo rimozione manuale\n",
    "n_feature_post_manuale = train_final_demo_selected.shape[1]\n",
    "\n",
    "\n",
    "# === MODELLAZIONE CON RANDOM FOREST (300 estimatori) PER ADHD USANDO DATI DEMOGRAFICI ===\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Features e target\n",
    "X = train_final_demo_selected.drop(columns=['participant_id', 'ADHD_Outcome'])\n",
    "y = train_final_demo_selected['ADHD_Outcome'].astype(int)\n",
    "\n",
    "# Cross-validation stratificata su ADHD_Outcome\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Liste per salvare i risultati di ogni fold\n",
    "acc_scores_adhd = []\n",
    "f1_scores_adhd = []\n",
    "\n",
    "# Cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    print(f\"  Dimensione X_train: {X_train.shape}\")\n",
    "    print(f\"  Dimensione X_test: {X_test.shape}\")\n",
    "    print(f\"  Dimensione y_train: {y_train.shape}\")\n",
    "    print(f\"  Dimensione y_test: {y_test.shape}\")\n",
    "    print(f\"  Valori unici in y_train: {np.unique(y_train)}\")\n",
    "    print(f\"  Valori unici in y_test: {np.unique(y_test)}\")\n",
    "\n",
    "    # === Standardizzazione === (facoltativa per Random Forest, ma la manteniamo per coerenza)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # === Modello Random Forest ===\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "    print(f\"  Predizioni y_pred (prime 5): {y_pred[:5]}\")\n",
    "    print(f\"  Valori reali y_test (prime 5): {y_test[:5].values}\")\n",
    "\n",
    "    # Metriche per questo fold\n",
    "    acc_scores_adhd.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores_adhd.append(f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# === RISULTATI FINALI ===\n",
    "print(\"\\n=== Media delle metriche su 10 fold ===\")\n",
    "print(f\"F1-score medio ADHD_Outcome: {np.mean(f1_scores_adhd):.4f}\")\n",
    "print(f\"Deviazione standard F1-score ADHD_Outcome: {np.std(f1_scores_adhd):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bc46f21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:21:06.851671Z",
     "iopub.status.busy": "2025-07-02T14:21:06.851195Z",
     "iopub.status.idle": "2025-07-02T14:21:36.806460Z",
     "shell.execute_reply": "2025-07-02T14:21:36.804733Z"
    },
    "papermill": {
     "duration": 29.966533,
     "end_time": "2025-07-02T14:21:36.809232",
     "exception": false,
     "start_time": "2025-07-02T14:21:06.842699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RISULTATI F1-SCORE ===\n",
      "ðŸ“Š Feature Selection AUTOMATICA (SelectKBest):\n",
      "   âž¤ F1-score medio: 0.8516\n",
      "   âž¤ Deviazione standard: 0.0247\n",
      "\n",
      "ðŸ›  Feature Selection MANUALE:\n",
      "   âž¤ F1-score medio: 0.8566\n",
      "   âž¤ Deviazione standard: 0.0288\n"
     ]
    }
   ],
   "source": [
    "# === FEATURE SELECTION MANUALE PER DATI DEMOGRAFICI ===\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# COPIA ORIGINALE DEL DATASET (se vuoi riutilizzare train_final_demo dopo)\n",
    "train_final_demo_copy = train_final_demo.copy()\n",
    "\n",
    "# === AUTOMATICA ===\n",
    "features_da_eliminare = [\"Basic_Demos_Study_Site_2\", \"Basic_Demos_Study_Site_3\", \"Basic_Demos_Study_Site_4\", \"MRI_Track_Scan_Location\"]\n",
    "train_final_demo_auto = train_final_demo_copy.drop(columns=features_da_eliminare, errors='ignore')\n",
    "\n",
    "colonne_da_aggiungere = ['participant_id','ADHD_Outcome']\n",
    "colonne_da_aggiungere_presenti = [col for col in colonne_da_aggiungere if col in train_final_demo_auto.columns]\n",
    "\n",
    "train_numeriche = train_final_demo_auto.select_dtypes(include=['int64', 'float64'])\n",
    "feature_data = train_numeriche.drop(columns=[col for col in colonne_da_aggiungere_presenti if col in train_numeriche.columns], errors='ignore')\n",
    "\n",
    "y_kbest = train_final_demo_auto['ADHD_Outcome'].astype(int)\n",
    "\n",
    "k = 26\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "X_selected = selector.fit_transform(feature_data, y_kbest)\n",
    "\n",
    "feature_mask = selector.get_support()\n",
    "selected_features = feature_data.columns[feature_mask]\n",
    "\n",
    "train_final_demo_selected_auto = pd.concat(\n",
    "    [train_final_demo_auto[colonne_da_aggiungere_presenti], feature_data[selected_features]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# === RANDOM FOREST CON FEATURE SELECTION AUTOMATICA ===\n",
    "X = train_final_demo_selected_auto.drop(columns=['participant_id', 'ADHD_Outcome'])\n",
    "y = train_final_demo_selected_auto['ADHD_Outcome'].astype(int)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "f1_scores_auto = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=300, class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "    y_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "    f1_scores_auto.append(f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# === MANUALE ===\n",
    "train_final_demo_manu = train_final_demo_copy.drop(columns=features_da_eliminare, errors='ignore')\n",
    "\n",
    "X = train_final_demo_manu.drop(columns=['participant_id', 'ADHD_Outcome'])\n",
    "y = train_final_demo_manu['ADHD_Outcome'].astype(int)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "f1_scores_manu = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=300, class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "    y_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "    f1_scores_manu.append(f1_score(y_test, y_pred))\n",
    "\n",
    "# === RISULTATI FINALI ===\n",
    "print(\"\\n=== RISULTATI F1-SCORE ===\")\n",
    "print(\"ðŸ“Š Feature Selection AUTOMATICA (SelectKBest):\")\n",
    "print(f\"   âž¤ F1-score medio: {np.mean(f1_scores_auto):.4f}\")\n",
    "print(f\"   âž¤ Deviazione standard: {np.std(f1_scores_auto):.4f}\")\n",
    "\n",
    "print(\"\\nðŸ›  Feature Selection MANUALE:\")\n",
    "print(f\"   âž¤ F1-score medio: {np.mean(f1_scores_manu):.4f}\")\n",
    "print(f\"   âž¤ Deviazione standard: {np.std(f1_scores_manu):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a64da2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T14:21:36.826472Z",
     "iopub.status.busy": "2025-07-02T14:21:36.825812Z",
     "iopub.status.idle": "2025-07-02T14:21:36.839675Z",
     "shell.execute_reply": "2025-07-02T14:21:36.838301Z"
    },
    "papermill": {
     "duration": 0.025284,
     "end_time": "2025-07-02T14:21:36.842380",
     "exception": false,
     "start_time": "2025-07-02T14:21:36.817096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'tesi_4.4_RF_ADHD_manuale.csv' salvato con successo!\n",
      "File 'tesi_4.4_RF_ADHD_mista.csv' salvato con successo!\n",
      "['tesi_4.4_RF_ADHD_mista.csv', 'tesi_4.4_SVC_sex_mista.csv', '__notebook__.ipynb', 'tesi_4.4_SVC_sex_manuale.csv', 'tesi_4.4_RF_ADHD_manuale.csv']\n"
     ]
    }
   ],
   "source": [
    "f1_scores_ADHD_manu = pd.DataFrame(f1_scores_manu, columns=[\"F1_ADHD_score\"])\n",
    "f1_scores_ADHD_manu.to_csv('tesi_4.4_RF_ADHD_manuale.csv', index=False)\n",
    "print(\"File 'tesi_4.4_RF_ADHD_manuale.csv' salvato con successo!\")\n",
    "f1_scores_ADHD_manu.head()\n",
    "\n",
    "f1_scores_ADHD_auto = pd.DataFrame(f1_scores_auto, columns=[\"F1_ADHD_score\"])\n",
    "f1_scores_ADHD_auto.to_csv('tesi_4.4_RF_ADHD_mista.csv', index=False)\n",
    "print(\"File 'tesi_4.4_RF_ADHD_mista.csv' salvato con successo!\")\n",
    "f1_scores_sex_auto.head()\n",
    "\n",
    "\n",
    "import os\n",
    "print(os.listdir('.')) # Mostra i file nella directory corrente"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11498594,
     "sourceId": 90566,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 255.390361,
   "end_time": "2025-07-02T14:21:37.775929",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-02T14:17:22.385568",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
